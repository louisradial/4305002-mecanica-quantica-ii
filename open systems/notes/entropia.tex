% vim: spl=pt
\chapter{Entropia em sistemas quânticos} 
Consideramos a função contínua \(s : [0,1] \to [0, \frac1e]\) dada por
\begin{equation}
    s(x) = \begin{cases}
        -x \ln x, &\text{se } x \in (0,1]\\
        0,&\text{se } x = 0.
    \end{cases}
\end{equation}
Essa função é côncava\cite{barata} e, portanto, vale
\begin{equation}
    s\left(\sum_{j = 1}^{N} \lambda_j x_j\right) \geq \sum_{j = 1}^{N} \lambda_j s(x_j)
\end{equation}
sempre que \(x_j \in [0,1]\) e \(\lambda_j \in [0,1]\) com \(\sum_{j = 1}^N \lambda_j = 1.\)

\section{Entropia de von Neumann}
O funcional definido no espaço de matrizes densidade por \(S(\rho) = \Tr(s(\rho))\) é denominado de \emph{entropia de von Neumann}. Doravante (e na literatura) escreveremos apenas \(S(\rho) = -\Tr(\rho \ln \rho),\) entendendo que \(-\rho \ln \rho = s(\rho).\) Da positividade de uma matriz densidade e da condição de traço unitário, sabemos que
\begin{equation}
    \rho = \sum_i p_i \ketbra{i}{i},\;\text{com}\; p_i \in [0,1]\;\text{e}\; \sum_i p_i = 1,
\end{equation}
portanto
\begin{equation}
    S(\rho) = - \sum_i p_i \ln p_i,
\end{equation}
isto é, a entropia de von Neumann é equivalente à entropia de Shannon para um estado \(\rho.\) Dessa forma, \(S(\rho)\) expressa a falta de informação de um estado de mistura \(\rho\) sobre a realização de um estado puro \(\ket{i}\). Essa interpretação ainda pode ser posta ao expressar a propriedade de concavidade,
\begin{equation}
    S\left(\sum_{j = 1}^{N} \lambda_j \rho_j\right) \geq \sum_{j = 1}^{N} \lambda_j S(\rho_j),
\end{equation}
onde vemos que a falta de informação é maior para um estado \(\rho = \sum_{j = 1}^N \lambda_j \rho_j\) do que a média da falta de informação dos estados constituintes \(\rho_j.\)

Para um sistema bipartite \(\mathscr{H} = \mathscr{H}_1 \otimes \mathscr{H}_2\), temos em geral a propriedade de subaditividade
\begin{equation}
    S(\rho) \leq S(\rho^{(1)}) + S(\rho^{(2)}),
\end{equation}
onde \(\rho^{(1)} = \Tr_2 \rho\) e \(\rho^{(2)} = \Tr_1 \rho\) são os estados reduzidos dos subsistemas. A igualdade se dá no caso em que o estado \(\rho\) não apresenta correlação, \(\rho = \rho^{(1)} \otimes \rho^{(2)},\) já que
\begin{align}
    S(\rho^{(1)} \otimes \rho^{(2)}) &= -\sum_i \sum_j p^{(1)}_i p_j^{(2)} \ln(p^{(1)}_i p^{(2)}_j)\\
                                     &= - \sum_i p^{(1)}_i \ln p^{(1)}_i \sum_j p^{(2)}_j - \sum_i p^{(1)}_i  \sum_j p^{(2)}_j\ln p^{(2)}_j\\
                                     &= S(\rho^{(1)}) + S(\rho^{(2)}).
\end{align}
A subaditividade da entropia de von Neumann estabelece que ao tomar o traço parcial de cada componente do sistema perdemos informação, com a aditividade de sistemas sem correlação sendo familiar à extensividade da entropia na Termodinâmica.

Uma matriz densidade \(\rho\) representa um estado puro se tem um único autovalor igual a 1. Essa condição é equivalente a entropia de von Neumann se anular. De fato, da expressão
\begin{equation}
    S(\rho) = -\sum_i p_i \ln p_i,
\end{equation}
vemos que \(S(\rho) = 0\) se e somente se \(p_i \in \set{0,1}\) para todos os estados da base, já que cada termo \(- p_i \ln p_i\) é não negativo. De \(\Tr\rho = 1,\) concluímos que \(S(\rho) = 0\) se e somente se existe apenas um \(p_i = 1\) e os demais se anulam. Como os coeficientes \(p_i\) são elementos do espectro de \(\rho,\) concluímos que \(S(\rho) = 0\) se e somente se \(\rho\) é um estado puro. Podemos resumir esta equivalência na propriedade
\begin{equation}
    S(\rho) \geq 0,
\end{equation}
onde a igualdade só vale se e somente se \(\rho\) é um estado puro.

Vamos supor que \(\rho\) tem \(n\) autovalores não nulos. Então, por uma transformação unitária, se necessário, podemos escrever
\begin{equation}
    \rho = \sum_{i = 1}^n p_i \ketbra{i}{i}
\end{equation}
mesmo que o espaço de Hilbert não tenha dimensão finita. Para determinar o valor máximo da entropia de von Neumann, variamos \(p_i\) com o vínculo \(\sum_{i = 1}^n p_i = 1,\) portanto com um multiplicador de Lagrange, temos
\begin{equation}
    \sum_{i = 1}^n (\ln p_i + \lambda + 1) \dli{p_i} + \left(\sum_{i=1}^n p_i - 1\right)\dli{\lambda} = 0 \implies \begin{cases}
        p_i = e^{-(\lambda+1)}\\
        \sum_{i = 1}^n p_i = 1
    \end{cases} \implies p_i = \frac1n,
\end{equation}
logo as matrizes densidade que maximizam a entropia são da forma
\begin{equation}
    \rho_* = \sum_{i = 1}^n \frac1n \ketbra{i}{i},
\end{equation}
com
\begin{equation}
    S(\rho_*) = \ln n.
\end{equation}
Assim, em sistemas de dimensão finita sempre temos
\begin{equation}
    0 \leq S(\rho) \leq \ln d,
\end{equation}
onde \(d\) é a dimensão do espaço de Hilbert e a matriz densidade que maximiza a entropia é \(\frac1d \unity\).

É importante notar que a entropia de von Neumann depende apenas do espectro de um estado e, portanto, invariante sob transformações unitárias. Dessa forma, temos 
\begin{equation}
    S(U \rho \herm{U}) = S(\rho)
\end{equation}
para qualquer operador unitário \(U\). Em particular, a entropia de von Neumann é constante no tempo para sistemas fechados, e, portanto, a evolução temporal leva estados puros em estados puros.

\section{Entropia relativa}
Relacionada com a entropia de von Neumann, definimos a \emph{entropia relativa} entre matrizes densidade \(\rho\) e \(\sigma\) por
\begin{equation}
    S(\rho|\sigma) = \Tr \rho \ln \rho - \Tr \rho \ln \sigma.
\end{equation}
Esse funcional satisfaz\cite{breuer}
\begin{equation}
    S(\rho|\sigma) \geq 0,
\end{equation}
\begin{equation}
    S(U \rho \herm{U}| U\sigma \herm{U}) = S(\rho | \sigma),
\end{equation}
assim como a entropia de von Neumann. 

Considerando um sistema bipartite novamente, temos
\begin{align}
    \entropy{\rho}{\rho^{(1)}\otimes \rho^{(2)}} &= - \Tr( \rho \ln \rho^{(1)} \otimes \rho^{(2)}) - S(\rho)\\
                                                 &= -\Tr\left[\rho \ln \left(\rho^{(1)}\otimes \unity_2\right)\right] -\Tr\left[\rho \ln \left(\unity_1\otimes \rho^{(2)}\right)\right] - S(\rho)\\
                                                 &= S(\rho^{(1)}) + S(\rho^{(2)}) - S(\rho),
\end{align}
onde usamos que podemos escrever \(\rho = \rho^{(1)} \otimes \rho^{(2)} + C\) com \(\Tr(C) = \Tr_1(C) = \Tr_2(C) = 0.\) Neste caso, a entropia relativa mede a diferença de entropia devido à correlação \(C.\) Ainda, para estados \(\rho\) e \(\sigma\) do sistema composto, vale
\begin{equation}
    \entropy{\rho^{(1)}}{\sigma^{(1)}} \leq \entropy{\rho}{\sigma},\label{eq:relS}
\end{equation}
onde \(\rho^{(1)} = \Tr_2\rho\) e \(\sigma^{(1)} = \Tr_2\sigma\) são os estados reduzidos.
